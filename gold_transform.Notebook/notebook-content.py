# Fabric notebook source

# METADATA ********************

# META {
# META   "kernel_info": {
# META     "name": "synapse_pyspark"
# META   },
# META   "dependencies": {
# META     "lakehouse": {
# META       "default_lakehouse": "e9496f5a-dcf6-4991-91e3-77a98b77eb65",
# META       "default_lakehouse_name": "gold_consoto",
# META       "default_lakehouse_workspace_id": "3a92de98-c671-477a-b7a2-694924bba5b2",
# META       "known_lakehouses": [
# META         {
# META           "id": "e9496f5a-dcf6-4991-91e3-77a98b77eb65"
# META         }
# META       ]
# META     }
# META   }
# META }

# CELL ********************

# Welcome to your new notebook
# Type here in the cell editor to add code!


# METADATA ********************

# META {
# META   "language": "python",
# META   "language_group": "synapse_pyspark"
# META }

# CELL ********************

sales_src = spark.sql("SELECT * FROM gold_consoto.sales_src" )
display(sales_src)

# METADATA ********************

# META {
# META   "language": "python",
# META   "language_group": "synapse_pyspark"
# META }

# CELL ********************

# Code generated by Data Wrangler for PySpark DataFrame

def clean_data(sales_src):
    # Rename column 'OrderDate' to 'OrderDateKey'
    sales_src = sales_src.withColumnRenamed('OrderDate', 'OrderDateKey')
    # Rename column 'DeliveryDate' to 'DeliveryDateKey'
    sales_src = sales_src.withColumnRenamed('DeliveryDate', 'DeliveryDateKey')
    return sales_src

sales_src_clean = clean_data(sales_src)
display(sales_src_clean)


# METADATA ********************

# META {
# META   "language": "python",
# META   "language_group": "synapse_pyspark"
# META }

# CELL ********************

# Load the data into a Delta table
table_name = "fct_sales"  # Replace with your desired table name
sales_src_clean.write.format("delta").mode("Overwrite"). saveAsTable(table_name)

# METADATA ********************

# META {
# META   "language": "python",
# META   "language_group": "synapse_pyspark"
# META }

# CELL ********************

customer_src = spark.sql("SELECT * FROM gold_consoto.customer_src")
display(customer_src)

# METADATA ********************

# META {
# META   "language": "python",
# META   "language_group": "synapse_pyspark"
# META }

# CELL ********************

# Load the data into a Delta table
table_name = "dim_customer"  # Replace with your desired table name
customer_src.write.format("delta").mode("Overwrite").saveAsTable(table_name)

# METADATA ********************

# META {
# META   "language": "python",
# META   "language_group": "synapse_pyspark"
# META }

# CELL ********************

currencyexchange_src = spark.sql("SELECT * FROM gold_consoto.currencyexchange_src")
display(currencyexchange_src)

# METADATA ********************

# META {
# META   "language": "python",
# META   "language_group": "synapse_pyspark"
# META }

# CELL ********************

# Code generated by Data Wrangler for PySpark DataFrame

from pyspark.sql import functions as F
from pyspark.sql import types as T

def clean_data(currencyexchange_src):
    # Change column type to string for column: 'Date'
    currencyexchange_src = currencyexchange_src.withColumn('Date', currencyexchange_src['Date'].cast(T.StringType()))
    # Replace all instances of "-" with "" in column: 'Date'
    currencyexchange_src = currencyexchange_src.withColumn('Date', F.regexp_replace('Date', "(?i)-", ""))
    # Change column type to int64 for column: 'Date'
    currencyexchange_src = currencyexchange_src.withColumn('Date', currencyexchange_src['Date'].cast(T.LongType()))
    # Rename column 'Date' to 'DateKey'
    currencyexchange_src = currencyexchange_src.withColumnRenamed('Date', 'DateKey')
    return currencyexchange_src

currencyexchange_src_clean = clean_data(currencyexchange_src)
display(currencyexchange_src_clean)

# METADATA ********************

# META {
# META   "language": "python",
# META   "language_group": "synapse_pyspark"
# META }

# CELL ********************

# Load the data into a Delta table
table_name = "fct_currencyexchange"  # Replace with your desired table name
currencyexchange_src_clean.write.format("delta").mode("Overwrite").saveAsTable(table_name)

# METADATA ********************

# META {
# META   "language": "python",
# META   "language_group": "synapse_pyspark"
# META }

# CELL ********************

date_src = spark.sql("SELECT * FROM gold_consoto.date_src")
display(date_src)

# METADATA ********************

# META {
# META   "language": "python",
# META   "language_group": "synapse_pyspark"
# META }

# CELL ********************

# Load the data into a Delta table
table_name = "dim_date"  # Replace with your desired table name
date_src.write.format("delta").mode("Overwrite").saveAsTable(table_name)

# METADATA ********************

# META {
# META   "language": "python",
# META   "language_group": "synapse_pyspark"
# META }

# CELL ********************

store_src = spark.sql("SELECT * FROM gold_consoto.store_src")
display(store_src)

# METADATA ********************

# META {
# META   "language": "python",
# META   "language_group": "synapse_pyspark"
# META }

# CELL ********************

# Load the data into a Delta table
table_name = "dim_store"  # Replace with your desired table name
store_src.write.format("delta").mode("Overwrite").saveAsTable(table_name)

# METADATA ********************

# META {
# META   "language": "python",
# META   "language_group": "synapse_pyspark"
# META }

# CELL ********************

product_src = spark.sql("SELECT * FROM gold_consoto.product_src")
display(product_src)

# METADATA ********************

# META {
# META   "language": "python",
# META   "language_group": "synapse_pyspark"
# META }

# CELL ********************

# Load the data into a Delta table
table_name = "dim_product"  # Replace with your desired table name
product_src.write.format("delta").mode("Overwrite").saveAsTable(table_name)

# METADATA ********************

# META {
# META   "language": "python",
# META   "language_group": "synapse_pyspark"
# META }
